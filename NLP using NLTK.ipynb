{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44186c56",
   "metadata": {},
   "source": [
    "### Natural language processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173c6689",
   "metadata": {},
   "source": [
    "Natural Language Processing : \n",
    "    \n",
    "- Linguistics + Data Science + Machine Learning Model \n",
    "\n",
    "- branch of artificial intelligence to decipher language structures \n",
    "\n",
    "Segmentation : break out each sentences by full stops.\n",
    "    \n",
    "Tokenization : each word is a token. \n",
    "    \n",
    "Stop words : remove meaningless words. \n",
    "    \n",
    "Stemming : normalize words to the basic root ( wait, waiting -> wait ) \n",
    "    \n",
    "Lemmatization : it's the same as stemming but will generate an actual words ( sometimes stemming generate false words  by cutting the end/start prefix of a words. ) \n",
    "    \n",
    "Part of speech (POS) tagging : add noun-verb-adj tag to the words. \n",
    "    \n",
    "Name entity recognition (NER) : catergorized name, geographical, monument tag without human analysis. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb2141aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Millions of people across the UK and beyond have celebrated the coronation of King Charles III - a symbolic ceremony combining a religious service and pageantry. The ceremony was held at Westminster Abbey, with the King becoming the 40th reigning monarch to be crowned there since 1066. Queen Camilla was crowned alongside him before a huge parade back to Buckingham Palace. Here's how the day of splendour and formality, which featured customs dating back more than 1,000 years, unfolded.\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Millions of people across the UK and beyond have celebrated the coronation of King Charles III - a symbolic ceremony combining a religious service and pageantry. The ceremony was held at Westminster Abbey, with the King becoming the 40th reigning monarch to be crowned there since 1066. Queen Camilla was crowned alongside him before a huge parade back to Buckingham Palace. Here's how the day of splendour and formality, which featured customs dating back more than 1,000 years, unfolded.\"\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7daa8a",
   "metadata": {},
   "source": [
    "#### Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b726a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/yenle/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import \n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c717debc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Millions of people across the UK and beyond have celebrated the coronation of King Charles III - a symbolic ceremony combining a religious service and pageantry.',\n",
       " 'The ceremony was held at Westminster Abbey, with the King becoming the 40th reigning monarch to be crowned there since 1066.',\n",
       " 'Queen Camilla was crowned alongside him before a huge parade back to Buckingham Palace.',\n",
       " \"Here's how the day of splendour and formality, which featured customs dating back more than 1,000 years, unfolded.\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split text into sentences\n",
    "sentences = sent_tokenize(text)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27d7dde8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Queen Camilla was crowned alongside him before a huge parade back to Buckingham Palace.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#indexing sentences  :\n",
    "sentences[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c291e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Queen Camilla was crowned alongside him before a huge parade back to Buckingham Palace '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Punctuation removal\n",
    "import re\n",
    "\n",
    "# Remove punctuation characters - remove the dot \n",
    "text = re.sub(r\"[^a-zA-Z0-9]\", \" \", sentences[2]) \n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ff16b1",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fce5030c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9185e4cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Queen', 'Camilla', 'was', 'crowned', 'alongside', 'him', 'before', 'a', 'huge', 'parade', 'back', 'to', 'Buckingham', 'Palace']\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(text)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde2696a",
   "metadata": {},
   "source": [
    "#### Removal of stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff38a405",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/yenle/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce7c78c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Queen', 'Camilla', 'crowned', 'alongside', 'huge', 'parade', 'back', 'Buckingham', 'Palace']\n"
     ]
    }
   ],
   "source": [
    "# Remove stop words\n",
    "words = [w for w in words if w not in stopwords.words(\"english\")]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91ebed99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# have a look at the stop words in nltk's corpus\n",
    "print(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9b696b",
   "metadata": {},
   "source": [
    "#### Stemming and lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9f0e6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/yenle/nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/yenle/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet') # download for lemmatization\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9e9dc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['queen', 'camilla', 'crown', 'alongsid', 'huge', 'parad', 'back', 'buckingham', 'palac']\n"
     ]
    }
   ],
   "source": [
    "# Stemming\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# Reduce words to their stems\n",
    "stemmed = [PorterStemmer().stem(w) for w in words]\n",
    "print(stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e1a818a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Queen', 'Camilla', 'crowned', 'alongside', 'huge', 'parade', 'back', 'Buckingham', 'Palace']\n"
     ]
    }
   ],
   "source": [
    "# Lemmatize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "# Reduce words to their root form\n",
    "lemmatized = [WordNetLemmatizer().lemmatize(w) for w in words]\n",
    "print(lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2dd0ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming output: ['wait', 'wait', 'studi', 'studi', 'comput']\n",
      "Lemmatization output: ['wait', 'waiting', 'study', 'studying', 'computer']\n"
     ]
    }
   ],
   "source": [
    "# Another stemming and lemmatization example\n",
    "words2 = ['wait', 'waiting' , 'studies', 'studying', 'computers']\n",
    "\n",
    "# Stemming\n",
    "# Reduce words to their stems\n",
    "stemmed = [PorterStemmer().stem(w) for w in words2]\n",
    "print(\"Stemming output: {}\".format(stemmed))\n",
    "\n",
    "# Lemmatization\n",
    "# Reduce words to their root form\n",
    "lemmatized = [WordNetLemmatizer().lemmatize(w) for w in words2]\n",
    "print(\"Lemmatization output: {}\".format(lemmatized))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900c5903",
   "metadata": {},
   "source": [
    "#### Part of speech tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e4145dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/yenle/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/yenle/nltk_data...\n",
      "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c95f4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "186f3347",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Queen', 'NNP'),\n",
       " ('Camilla', 'NNP'),\n",
       " ('crowned', 'VBD'),\n",
       " ('alongside', 'RB'),\n",
       " ('huge', 'JJ'),\n",
       " ('parade', 'NN'),\n",
       " ('back', 'RB'),\n",
       " ('Buckingham', 'NNP'),\n",
       " ('Palace', 'NNP')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tag each word with part of speech\n",
    "pos_tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "228ed682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPOS\\n\\nCC: It is the conjunction of coordinating\\nCD: It is a digit of cardinal\\nDT: It is the determiner\\nEX: Existential\\nFW: It is a foreign word\\nIN: Preposition and conjunction\\nJJ: Adjective\\nJJR and JJS: Adjective and superlative\\nLS: List marker\\nMD: Modal\\nNN: Singular noun\\nNNS, NNP, NNPS: Proper and plural noun\\nPDT: Predeterminer\\nWRB: Adverb of wh\\nWP$: Possessive wh\\nWP: Pronoun of wh\\nWDT: Determiner of wp\\nVBZ: Verb\\nVBP, VBN, VBG, VBD, VB: Forms of verbs\\nUH: Interjection\\nTO: To go\\nRP: Particle\\nRBS, RB, RBR: Adverb\\nPRP, PRP$: Pronoun personal and professional\\n\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "POS\n",
    "\n",
    "CC: It is the conjunction of coordinating\n",
    "CD: It is a digit of cardinal\n",
    "DT: It is the determiner\n",
    "EX: Existential\n",
    "FW: It is a foreign word\n",
    "IN: Preposition and conjunction\n",
    "JJ: Adjective\n",
    "JJR and JJS: Adjective and superlative\n",
    "LS: List marker\n",
    "MD: Modal\n",
    "NN: Singular noun\n",
    "NNS, NNP, NNPS: Proper and plural noun\n",
    "PDT: Predeterminer\n",
    "WRB: Adverb of wh\n",
    "WP$: Possessive wh\n",
    "WP: Pronoun of wh\n",
    "WDT: Determiner of wp\n",
    "VBZ: Verb\n",
    "VBP, VBN, VBG, VBD, VB: Forms of verbs\n",
    "UH: Interjection\n",
    "TO: To go\n",
    "RP: Particle\n",
    "RBS, RB, RBR: Adverb\n",
    "PRP, PRP$: Pronoun personal and professional\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a8864b",
   "metadata": {},
   "source": [
    "#### Named entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b1bb436",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /Users/yenle/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import ne_chunk\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7fc67a3c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (PERSON Queen/NNP)\n",
      "  (PERSON Camilla/NNP)\n",
      "  was/VBD\n",
      "  crowned/VBN\n",
      "  alongside/RB\n",
      "  him/PRP\n",
      "  before/IN\n",
      "  a/DT\n",
      "  huge/JJ\n",
      "  parade/NN\n",
      "  back/RB\n",
      "  to/TO\n",
      "  (PERSON Buckingham/NNP Palace/NNP)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "#name entity recognition tree \n",
    "ner_tree = ne_chunk(pos_tag(word_tokenize(sentences[2])))\n",
    "print(ner_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbd52191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  Millions/NNS\n",
      "  of/IN\n",
      "  people/NNS\n",
      "  across/IN\n",
      "  the/DT\n",
      "  (ORGANIZATION UK/NNP)\n",
      "  and/CC\n",
      "  beyond/IN\n",
      "  have/VBP\n",
      "  celebrated/VBN\n",
      "  the/DT\n",
      "  coronation/NN\n",
      "  of/IN\n",
      "  King/NNP\n",
      "  (PERSON Charles/NNP III/NNP)\n",
      "  -/:\n",
      "  a/DT\n",
      "  symbolic/JJ\n",
      "  ceremony/NN\n",
      "  combining/VBG\n",
      "  a/DT\n",
      "  religious/JJ\n",
      "  service/NN\n",
      "  and/CC\n",
      "  pageantry/NN\n",
      "  ./.\n",
      "  The/DT\n",
      "  ceremony/NN\n",
      "  was/VBD\n",
      "  held/VBN\n",
      "  at/IN\n",
      "  (ORGANIZATION Westminster/NNP Abbey/NNP)\n",
      "  ,/,\n",
      "  with/IN\n",
      "  the/DT\n",
      "  King/NNP\n",
      "  becoming/VBG\n",
      "  the/DT\n",
      "  40th/CD\n",
      "  reigning/VBG\n",
      "  monarch/NN\n",
      "  to/TO\n",
      "  be/VB\n",
      "  crowned/VBN\n",
      "  there/RB\n",
      "  since/IN\n",
      "  1066/CD\n",
      "  ./.\n",
      "  (PERSON Queen/NNP Camilla/NNP)\n",
      "  was/VBD\n",
      "  crowned/VBN\n",
      "  alongside/RB\n",
      "  him/PRP\n",
      "  before/IN\n",
      "  a/DT\n",
      "  huge/JJ\n",
      "  parade/NN\n",
      "  back/RB\n",
      "  to/TO\n",
      "  (PERSON Buckingham/NNP Palace/NNP)\n",
      "  ./.\n",
      "  Here/RB\n",
      "  's/VBZ\n",
      "  how/WRB\n",
      "  the/DT\n",
      "  day/NN\n",
      "  of/IN\n",
      "  splendour/NN\n",
      "  and/CC\n",
      "  formality/NN\n",
      "  ,/,\n",
      "  which/WDT\n",
      "  featured/VBD\n",
      "  customs/NNS\n",
      "  dating/VBG\n",
      "  back/RB\n",
      "  more/JJR\n",
      "  than/IN\n",
      "  1,000/CD\n",
      "  years/NNS\n",
      "  ,/,\n",
      "  unfolded/VBD\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "text = \"Millions of people across the UK and beyond have celebrated the coronation of King Charles III - a symbolic ceremony combining a religious service and pageantry. The ceremony was held at Westminster Abbey, with the King becoming the 40th reigning monarch to be crowned there since 1066. Queen Camilla was crowned alongside him before a huge parade back to Buckingham Palace. Here's how the day of splendour and formality, which featured customs dating back more than 1,000 years, unfolded.\"\n",
    "\n",
    "ner_tree = ne_chunk(pos_tag(word_tokenize(text)))\n",
    "print(ner_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac91fc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (PERSON Twitter/NNP)\n",
      "  (ORGANIZATION CEO/NNP Elon/NNP Musk/NNP)\n",
      "  arrived/VBD\n",
      "  at/IN\n",
      "  the/DT\n",
      "  (FACILITY Staples/NNP Center/NNP)\n",
      "  in/IN\n",
      "  (GPE Los/NNP Angeles/NNP)\n",
      "  ,/,\n",
      "  (GPE California/NNP)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "text = \"Twitter CEO Elon Musk arrived at the Staples Center in Los Angeles, California. \"\n",
    "ner_tree = ne_chunk(pos_tag(word_tokenize(text)))\n",
    "print(ner_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ab0468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df5a63a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f49e02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd392f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042eaf5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eb5d10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1f5ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826f8bba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640818b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373f8779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0893d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3beff7f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618b206f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4210b415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6e614f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
